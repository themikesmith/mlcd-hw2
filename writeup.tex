%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%This is a science homework template. Modify the preamble to suit your needs. 
%The junk text is   there for you to immediately see how the headers/footers look at first 
%typesetting.


\documentclass[12pt]{article}

%AMS-TeX packages
\usepackage{amssymb,amsmath,amsthm} 
%geometry (sets margin) and other useful packages
\usepackage[margin=1.25in]{geometry}
\usepackage{graphicx,placeins}


%
%Redefining sections as problems
%
\makeatletter
\newenvironment{problem}{\@startsection
       {section}
       {1}
       {-.2em}
       {-3.5ex plus -1ex minus -.2ex}
       {2.3ex plus .2ex}
       {\pagebreak[3]%forces pagebreak when space is small; use \eject for better results
       \large\bf\noindent{Problem }
       }
       }
       {%\vspace{1ex}\begin{center} \rule{0.3\linewidth}{.3pt}\end{center}}
       \begin{center}\large\bf \ldots\ldots\ldots\end{center}}
\makeatother


%
%Fancy-header package to modify header/page numbering 
%
\usepackage{fancyhdr}
\pagestyle{fancy}
%\addtolength{\headwidth}{\marginparsep} %these change header-rule width
%\addtolength{\headwidth}{\marginparwidth}
\lhead{Problem \thesection}
\chead{} 
\rhead{\thepage} 
\lfoot{\small\scshape Machine Learning in Complex Domains} 
\cfoot{} 
\rfoot{\footnotesize PS \#2} 
\renewcommand{\headrulewidth}{.3pt} 
\renewcommand{\footrulewidth}{.3pt}
\setlength\voffset{-0.25in}
\setlength\textheight{648pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%Contents of problem set
%    
\begin{document}

\title{MLCD 2: Robots and Such }
\author{Elan Hourticolon-Retzler and Mike Smith}

\maketitle

\thispagestyle{empty}

\begin{problem}{Parameter Sharing}


4.1.4 - Deliverables for estimate-params

Our estimate-params program is written in Java.  We have a driver 
program, a singleton Network class, a MotionModel class, an 
ObservationModel class, and a Constants class.

The network class has three methods, each of which are called in 
succession by the driver: read, train, and write.

In the read function we use assumptions specified about our models and 
the input format to determine sufficient statistics for each network; 
they are the number of rows I, the number of columns J, the number of 
landmarks L, and the number of time steps T.  We collect these in the 
method while reading the network file.

In the train function, we initialize our models with the applicable 
sufficient statistics.  We note that to compute the MAP estimate using
add-1 smoothing, we need to only maintain counts of times we observed 
each parameter p, and maintain counts of all possible instances where 
we could have observed said parameter p.  To implement add-1 smoothing, 
We initialize our observed counts of each p to 1, and our counts of 
chances of observation to 2.
For the motion model, we maintain two 4x1 arrays, one for successful 
moves in each of the 4 directions, and one for attempted moves in each 
of the 4 directions.
For the observation model, we maintain a four-dimensional array.  We 
have an IxJ array, and in each cell we store a two dimensional array 
which is information about observing walls and landmarks at that cell 
of the map.  This 2-d array is (4(1+L))x2, as for each cell we could 
observe a wall in each of the 4 directions, and we could observe any of
 the L landmarks in each of the 4 directions.  The remaining dimension 
x2 is to store the number of times we made observation $O_i$ at the cell 
(i,j), and the number of times we visited the cell (i,j) respectively.

In the writeCPD function, we loop over all time steps in the network.
For each time step, we output the same probabilities since we are 
sharing parameters.  For each time step, we output the results of the 
motion model, and those of the observation model.
For the motion model, we loop once over every previous row value.  For 
each of these values, we loop over every possible action, and print the
probability of the action's success given the previous row value, and
print the probability of the action's failure (if applicable).  
Analogously, we loop over every previous column value, and for each of 
these values, we loop over every possible action.  We print the 
probability of the action's success given the previous column value, and
print the probability of the action's failture (if applicable).
For the observation model, we loop once over every possible value of 
(i,j), and for each observation $O_i$, print the probability of making 
that observation ('yes'), and the probability of not making it ('no').

4.1.5  Analytical questions about shared parameterization

1. An important advantage of sharing parameters is the lesssening of the
effects of overfitting.  Explain why.  Why is this issue important when
doing parameter estimation in this assignment?

Sharing parameters lessens the effects of overfitting because we smooth
across all time steps, computing probabilities using data from all time
 steps.  By doing this, we increase our sample size.  If we did not 
share parameters, we would be computing probabilities of events at a 
given time, and we would need many more training trajectories both to 
accurately estimate probabilities, and to avoid many scenarios for which
we have no data.  Smoothing takes care of this, but the specific brand 
of smoothing that we use, add-1, does not adjust for the sample size, so
we end up smoothing an incredible amount relative to our unseen event.

This issue is important when doing our estimation in this assignment 
because we want our probabilities in the CPD to be meaningful, and to 
carry weight.  We also want to be able to predict the chance of an event
given a context that we never encounter (eg, transitioning from a 
position at a given time step after a move from a previous position in 
the previous time step), so it is important that we smooth, and assume 
that this probability is equal to the probability of being in a 
position after a move from a previous position.

2. Describe at least one property of the robot localization setting (with regard
to either the motion model or observation model) that you cannot model with the shared
parameterization in this assignment, but that you could model if we used an explicit
parameterization (i.e. we learn the entire CPT for particular positions or time steps). It
does not have to be a property of the environment that we described in this handout; you
can construct something relevant that you might like to model in this setting.

If the robot's legs wear out after a certain number of moves, the 
chances of a move failing greatly increase after time is greater than
this threshold.  Sharing parameters across all time steps doesn't allow
for us to capture this.

3. Describe a way to combine the advantages of both approaches. That is, come
up with a model design that can potentially learn unique values for all CPT entries, but
also has shared parameters which reduce overfitting. Sketch the idea in a few sentences,
and explain the advantages over the other models.\\

??? //TODO



\end{problem}{}

\begin{problem}{Inference}
4.2.1\\

1 and 3.\\

Describe the process you followed to make the clique tree. Note one or two
points in the process where you could have obtained a (slightly) different clique tree by
making different choices.\\

We noted that because of the problem domain and structure of the models,
we only needed the sufficient statistics from a network to be able to 
construct a clique tree for that network.  Given these statistics, we 
know how to convert the network to an undirected chordal graph and thus
get the set of maximal cliques.  They are as follows. \\
\textit{Observation Model:}\\
for every value of time $T=t_i$:\\
\indent	for each direction:\\
\indent \indent row t, col t, observe wall d t\\
\indent	for each direction:\\
\indent	\indent	for each landmark:\\
\indent	\indent	\indent	row t, col t, observe landmark L d t\\
\textit{Motion Model:}\\
for every value of time $T=t_i$, save $T=t_n$:\\
\indent	row t, row t+1, col t+1, action t\\
\indent	row t, col t, col t+1, action t\\
if $t=t_n$: \\
\indent	$Action_t$ \\

\noindent Note that we discussed with Dr Saria, and she advised us to switch to cliques of the following form given our motion model, even though they are not derived using the minimal triangulation of the graph:\\
\textit{Motion Model:}\\
for every value of time $T=t_i$, save $T=t_n$:\\
\indent	row t, col t+1, row t+1, col t+1, action t\\
if $t=t_n$: \\
\indent	$Action_t$ \\
\textit{Our clique trees built using the former method with minimal triangulation are in 'cliquetree-*.txt' files.  This naming convention contrasts with that used for our trees built using the latter method with larger cliques, which is 'cliquetree-*\_big.txt'.}\\
Given that we have these maximal cliques, create a cluster graph by 
going through all possible pairs $i,j$ of cliques (except where $i=j$), 
adding an edge ($i$ to $j$) to the graph if the number of variables in 
common between $i$ and $j$ is greater than 0.  The weight of each edge is
the number of variables in common along that edge.\\

We sort these edges in decreasing order by weight so that we can apply
a modified version of Kruskal's algorithm for finding a maximum spanning
tree.  We modify it because we note that our clique tree may not be 
fully connected, and that's okay.\\

Once we have our tree, we print it according to the output format.\\

There was one choice we made to make when creating a tree, such that if
we had taken a different path the tree would have differed.  For the 
variables at each time step, we had to choose between creating one of 
two new edges when generating the list of maximal cliques.  We close to
connect $Row_t$ to $Col_{t+1}$ where we instead could have chosen to make 
an edge between $Col_t$ and $Row{t+1}$.  This would affect our cliques, and
would therefore affect the vertices and edges of our clique tree.\\

2. [2 points] Demonstrate that the running intersection property holds 
in the resulting clique tree. A formal proof is not required, simply 
explain how this property holds.\\

\noindent The form of our clique tree is as follows:\\
\noindent \textit{Using our minimal triangulation trees:}\\
We note that this is simply a chain.  At each time $t$, we have a clique $G_t$ (row t, col t, action t, col t+1) connected to a clique $B_t$ (row t, action t, row r+1, col t+1), and a clique $G_t$ connected to cliques $R_{t}^{i}$ (row t, col t, observation i t).  $B_t$ connects to $G_{t+1}$ in the next time step.\\
\noindent \textit{Using our trees with larger cliques:}\\
We note that this is simply a chain, with each large clique at time $t$ (row t, col t, action t, row t+1, col t+1) having edges leading to the observations at time $t$ (row t, col t, observation $i$ at time t), and the next large clique at time $t+1$ (row t+1, col t+1, action t+1, row t+2, col t+2).\\

\noindent Because our cliques repeat the same structure across time steps, 
we can restrict our 'proof' to examining a small subset of contiguous
time steps in the clique tree, and by induction we can see that for the
whole tree it is true.  The final action $Action_t$ is a clique of size 1,
such that there are no edges, so the running intersection property holds. \\

4.\\

\noindent For a grid of size N by M and a sequence of T actions and observations (assume they are fully observed), what would be the computational complexity of computing the distribution over the final position at time T if we simply marginalized over a joint CPT?
What is the computational complexity of computing the distribution over the final position at time T using message passing in your clique tree?\\
The computational complexity of computing the distribution over the final position at time T if we simply marginalize over a joint CPT is as follows:\\
If we have $n$ variables, and the maximum cardinality out of all the variables is $c$, then the cost of marginalizing over the joint CPT is $c^n$.\\
The computational complexity of the clique tree message passing is as follows, from p358 of Koller:
Letting $c$ be the execution cost of message passing in a clique tree to one root (upward pass), the cost of obtaining the calibrated tree is $2c$.  One pass of the message passing algorithm involves every vertex sending a message to its 'downstream' neighbors, so it involves $v$ vertices.  When sending to vertex $j$, each vertex $i$ marginalizes out all its variables not in the sepset between its variables and $j$'s variables.  The number of variables marginalized is on the order of the size of the largest clique, which we'll call $k$.\\
We are given all actions and observations, as incremental evidence.  We could do it one of two ways.\\
\textit{We note that at most we have 3 vertices for each time step, if we use our minimal triangulation, and the largest clique size is 3.  This would make $v = 3T$, and $k = 3$.  We also could have at most 2 vertices for each time step, and the largest clique size is 5, which would make $v = 2T$ and $k = 5$.  We consider the latter case to be the worst case scenario, as we will see.}\\
\noindent - Let the cost of an operation on a factor be proportional to the size of the factor.  We could calibrate our tree based on our distribution's initial beliefs, with cost $2c = 2vk$.  Note that $k$ is the size of the largest clique, which means the size of the largest factor is $O(k)$.  We could then introduce our evidence set $E$, which has $O(T)$ actions, and $O(T n)$ observations, where $T$ is the number of time steps, and $n$ is the maximum number of observations at any time step.  We would therefore need to multiply in $O(2 T n)$ indicator functions, which has cost $O(2 T n x)$, where $x$ is the time needed to find an applicable clique at which to multiply any given indicator function.  We then would need to recalibrate the tree, which adds cost $2 v k$ again.  This is a total cost of $O(4 v k)$, which in our worst case scenario is $O(4 \cdot 2T \cdot 5) = O(40T)$.\\
\noindent - Assuming we only want to answer this one query, we can forego calibrating the clique tree first, and only calibrate it once after we multiply in the indicator factors with the evidence.  This brings us down to $O(20T)$.\\

\end{problem}{}

\begin{problem}{Bayesian Score for Bayesian Networks}

\begin{eqnarray*}
P( \mathcal{D} \mid \mathcal{G}) & = & 
\prod_i \prod _{\mathbf{u_{i}} \in Val(Pa^{\mathcal{G}}_{X_{i}})} 
\frac{\Gamma(\alpha^{\mathcal{G}}_{X_{i}\mid \mathbf{u}_{i}})}{\Gamma(\alpha^{\mathcal{G}}_{X_{i}\mid \mathbf{u}_{i}} + M[ \mathbf{u}_{i}])} 
\prod_{x_{i}^{j} \in Val(X_{i})} 
\left[ \frac{\Gamma(\alpha^{\mathcal{G}}_{x_{i}^{j}\mid \mathbf{u}_{i}} + M[ x_{i}^{j},\mathbf{u}_{i}])}{\Gamma(\alpha^{\mathcal{G}}_{x_{i}^{j}\mid \mathbf{u}_{i}} )} \right]\\
& = & 
\prod_i \prod _{\mathbf{u_{i}} \in Val(Pa^{\mathcal{G}}_{X_{i}})} 
A
\prod_{x_{i}^{j} \in Val(X_{i})} 
B\\
\end{eqnarray*}

\begin{eqnarray*}
p_{i} & = & \alpha^{\mathcal{G}}_{X_{i}\mid \mathbf{u}_{i}}\\
q_{i,j} & = & \alpha^{\mathcal{G}}_{x_{i}^{j}\mid \mathbf{u}_{i}} \\
\\
A & = & \frac{\Gamma(\alpha^{\mathcal{G}}_{X_{i}\mid \mathbf{u}_{i}})}{\Gamma(\alpha^{\mathcal{G}}_{X_{i}\mid \mathbf{u}_{i}} + M[ \mathbf{u}_{i}])} \\
& = & \frac{\Gamma(p_{i})}{\Gamma(p_{i} + M[ \mathbf{u}_{i}])} \\
& = & \frac{p_{i}^{(p_{i}-\frac{1}{2})} e^{-p_{i}}}{(p_{i} + M[ \mathbf{u}_{i}])^{(p_{i} + M[ \mathbf{u}_{i}] - \frac{1}{2})}e^{-(p_{i} + M[ \mathbf{u}_{i}]})} \\
& = & \frac{p_{i}^{(p_{i}-\frac{1}{2})} }{(p_{i} + M[ \mathbf{u}_{i}])^{(p_{i} + M[ \mathbf{u}_{i}] - \frac{1}{2})}} e^{-p_{i}+(p_{i} + M[ \mathbf{u}_{i}])} \\
& = & \frac{p_{i}^{(p_{i}-\frac{1}{2})} }{(p_{i} + M[ \mathbf{u}_{i}])^{(p_{i} + M[ \mathbf{u}_{i}] - \frac{1}{2})}} e^{ M[ \mathbf{u}_{i}]} \\
& = & p_{i}^{(p_{i}-\frac{1}{2})} 
	(p_{i} + M[ \mathbf{u}_{i}])^{-(p_{i} + M[ \mathbf{u}_{i}] - \frac{1}{2})} 
	e^{ M[ \mathbf{u}_{i}]} \\
\\
B & = & \frac{\Gamma(\alpha^{\mathcal{G}}_{x_{i}^{j}\mid \mathbf{u}_{i}} + M[ x_{i}^{j},\mathbf{u}_{i}])}{\Gamma(\alpha^{\mathcal{G}}_{x_{i}^{j}\mid \mathbf{u}_{i}} )}\\
& = & \frac{\Gamma(q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}])}{\Gamma(q_{i,j} )}\\
& = & \frac{(q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}])^{(q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}] -\frac{1}{2})}e^{-(q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}])}}{q_{i,j} ^{(q_{i,j} -\frac{1}{2})} e^{-q_{i,j} }}\\
& = & \frac{(q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}])^{(q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}] -\frac{1}{2})}}{q_{i,j} ^{(q_{i,j} -\frac{1}{2})} } 
	e^{-M[ x_{i}^{j},\mathbf{u}_{i}]}\\
& = & (q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}])^{(q_{i,j}  + M[ x_{i}^{j},\mathbf{u}_{i}] -\frac{1}{2})}
	q_{i,j} ^{-(q_{i,j} -\frac{1}{2})} 
	e^{-M[ x_{i}^{j},\mathbf{u}_{i}]}\\
\end{eqnarray*}

\begin{eqnarray*}
\ell(\hat{\mathbf{\theta}},\mathcal{D}) & = & 
	\sum^{n}_{i=1} \left[ \sum_{\mathbf{u_{i}} \in Val(Pa^{\mathcal{G}}_{X_{i}})}  \sum_{x_{i}}  \right]
	M[x_{i},\mathbf{u_{i}}] \log \hat{\mathbf{\theta}}_{x_{i} \mid \mathbf{u_{i}}}
\end{eqnarray*}

\end{problem}{}

\end{document}